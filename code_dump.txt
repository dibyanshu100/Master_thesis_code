import torch
import torch.nn.functional as F

**************************************************** Scaled VS Unscaled *****************************************************

def evaluate_on_scaled_loss(test_data, loss_formulation, data_type):
    config = train_config["training_2D"]
    device = config['device']
    batch = config['batch_size']
    epochs = config['epochs']
    model_final, model_initial = run_saved_model(loss_formulation, data_type)
    test_loader = make_batches(test_data, device, batch_size = batch, shuffle = False)

    loss_space = ['diffusion_loss_x', 'diffusion_loss_epsilon', 'diffusion_loss_v', 'diffusion_loss_score']
    test_loss_dict = {}
    for loss_type in loss_space:
        test_epoch_losses = []

        for epoch in tqdm(range(epochs)):
            model = model_final#model_initial if epoch == 0 else model_final
            test_batch_loss = 0
            model.eval()
            for batch,_ in test_loader:
                loss= l.scaled_loss(batch, model, device, loss_type)
                test_batch_loss += loss.item()
            test_epoch_losses.append(test_batch_loss/len(test_loader))
        
        test_loss_dict[loss_type] = test_epoch_losses
    
    return test_loss_dict

def scaled_loss(x, model, device, loss_type):

    t = torch.rand((x.size(0),1)).to(device)             
    alpha_t = torch.cos((torch.pi/2)*t)         
    sigma_t = torch.sin((torch.pi/2)*t)        
    noise = torch.randn_like(x).to(device)                
    x_t = alpha_t * x + sigma_t * noise
    input = torch.cat([x_t,t], dim=1)          
    noise_pred = model(input)

    if loss_type == 'diffusion_loss_epsilon':       
        scaling_coeff = 1
    if loss_type == 'diffusion_loss_x':
        scaling_coeff = (sigma_t**2)/((alpha_t**2)+1e-2)
    if loss_type == 'diffusion_loss_v':
        scaling_coeff = (alpha_t*(1+(sigma_t**2)/((alpha_t**2)+1e-2)))**2
    if loss_type == 'diffusion_loss_score':
        scaling_coeff = 1/(((alpha_t*sigma_t)**2)+1e-2)     

    # Calculate per-sample MSE loss
    sample_loss =  scaling_coeff * F.mse_loss(noise, noise_pred, reduction='none')                                
            
    return sample_loss.mean()

def run_saved_model(loss_formulation, data_type=None, sampling=None, plot_samples= False):
    """Run saved models"""
    config = train_config["training_2D"]
    hidden_dim = config['hidden_dim']
    x_dim = config['x_dim']
    device = config['device'] 
    model = Diffusion_Model_2D(input_dim = x_dim+1, hidden_dim = hidden_dim, output_dim = x_dim).to(device)

    # Untrained model
    initial_state = model.state_dict()
    untrained_model = model.__class__(input_dim=x_dim+1, hidden_dim=hidden_dim, output_dim=x_dim).to(device)
    untrained_model.load_state_dict(initial_state)

    # Final model
    state_dict_path = os.path.join('saved_models/', "Parameters_" + f"{loss_formulation.__name__}" + data_type)
    model.load_state_dict(torch.load(state_dict_path))
    final_model = model

    if plot_samples:
        all_samples = np.zeros((9, 2000, 2))
        step_counts = np.power(2, np.linspace(0, 9, 9)).astype(int)
        for idx, num_steps in enumerate(step_counts):
            samples = sampling(final_model, device, num_steps)
            all_samples[idx] = samples.detach().cpu().numpy()
        plot_generated_samples(all_samples, step_counts, f"{data_type}_{loss_formulation.__name__}_all_samples")
    
    return final_model, untrained_model


********************************************************************************************************************************


def evaluate_on_scaled_loss(test_data, loss_formulation, data_type):
    """ Function to compare weighted objectives to equivalent x objectives"""
    device = config['device']
    batch = config['batch_size']
    epochs = config['epochs']
    model= run_saved_model_2D(loss_formulation, data_type)
    test_loader = make_batches(test_data, device, batch_size = batch, shuffle = False)

    loss_space = ['diffusion_loss_x', 'diffusion_loss_epsilon', 'diffusion_loss_v', 'diffusion_loss_score']
    test_loss_dict = {}
    for loss_type in loss_space:
        test_epoch_losses = []
        for _ in tqdm(range(epochs)):
            test_batch_loss = 0
            model.eval()
            for batch,_ in test_loader:
                loss= l.scaled_loss(batch, model, device, loss_type)
                test_batch_loss += loss.item()
            test_epoch_losses.append(test_batch_loss/len(test_loader))
        
        test_loss_dict[loss_type] = test_epoch_losses
    
    return test_loss_dict

********************************************************************************************************************************
## Animation code
%matplotlib ipympl
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation, PillowWriter

epochs_to_plot = [i for i in range(0,100,5)] +[99]

# Initialize the plot
fig, ax = plt.subplots()
ax.set_xlabel("Time Steps")
ax.set_ylabel("Loss")
ax.set_title("Loss vs Timesteps at different Epochs")
ax.grid(True)

# Create an empty line object for the plot
line, = ax.plot([], [], label="Loss")
def init():
    line.set_data([], [])
    return line

# Function to update the plot for each epoch
def update(frame):
    pos = epochs_to_plot[frame]
    if pos < len(loss_vs_time_per_epoch):
        dictionary = loss_vs_time_per_epoch[pos]
        keys = list(dictionary.keys())
        values = list(dictionary.values())
        line.set_data(keys, values)
        line.set_label(f"Epoch {pos + 1}")
        ax.legend()
        ax.relim()
        ax.autoscale_view()
    return line

# Create the animation
ani = FuncAnimation(fig, update, frames=len(epochs_to_plot), init_func=init, blit=True, repeat=False)
writer = PillowWriter(fps=1)
ani.save("results/animation.gif", writer=writer)

# Show the plot
plt.legend()
plt.show()